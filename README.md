# LLM Puzzle Break Chrome Extension

Take a quick mental break with puzzles, riddles, and trivia questions generated by an AI! This Chrome extension provides a simple popup game where you can:

* Request puzzles based on type (Any, Trivia, Riddle, Logic) and difficulty (Easy, Medium, Hard).
* Submit your answers for AI evaluation.
* See the correct answer if you're wrong.
* Keep track of your score during the browser session.
* Get varied questions using recent puzzle history to guide the AI.

The extension relies on the Google Gemini API (you'll need your own API key).

## How it Works (Cognitive Layers)

The extension's background script (`background.js`) uses a conceptual 4-layer cognitive model to organize how it handles requests from the popup UI (`popup.js`). This structure helps separate concerns:

1.  **Memory (`memory.js`):** This layer handles persistent and semi-persistent data storage using Chrome's storage APIs.
    * Retrieves the user's Google AI API key (`chrome.storage.sync`) needed for LLM interactions.
    * Stores and retrieves the list of recently asked puzzle questions (`chrome.storage.session`) to help avoid immediate repetition.
    * Stores and retrieves the user's current game score (`chrome.storage.session`). Session storage typically clears when the browser is closed.

2.  **Perception (`puzzle_perception.js`):** This layer acts as the input interpreter for messages coming from the popup.
    * It receives messages like `getNewQuestion` (which includes the desired `difficulty` and `puzzleType`) or `evaluateAnswer` (which includes the `questionData` and the `userAnswer`).
    * It translates these raw messages into a standardized, structured format representing the user's immediate request (e.g., `{ type: 'REQUEST_NEW_PUZZLE', difficulty: 'Medium', puzzleType: 'Riddle' }` or `{ type: 'EVALUATE_ANSWER', ... }`). This structured request is then passed to the next layer.
    * *(LLM Note: While an LLM could theoretically be used here for complex intent analysis, in this extension, its role is simulated by simple message parsing).*

3.  **Decision-Making (`puzzle_decision_making.js`):** This layer determines the next logical step based on the interpreted request from the Perception layer.
    * It takes the structured request (e.g., `REQUEST_NEW_PUZZLE`).
    * It decides *what* action needs to be performed next. For `REQUEST_NEW_PUZZLE`, it decides the action is `GENERATE_PUZZLE`. For `EVALUATE_ANSWER`, it decides the action is `EVALUATE_WITH_LLM`.
    * It constructs an "action plan" object containing the action type and all necessary data for that action (e.g., `{ action: 'GENERATE_PUZZLE', difficulty: 'Medium', puzzleType: 'Riddle', askedHistory: [...] }`). This plan is passed to the Action layer.

4.  **Action (`puzzle_action.js`):** This layer executes the action plan generated by the Decision-Making layer, interacting with external services or APIs as needed.
    * It receives the action plan (e.g., `{ action: 'GENERATE_PUZZLE', ... }`) and the API key.
    * It calls the appropriate function in the `LLMService` module (`llm_service.js`).
    * For `GENERATE_PUZZLE`, it calls `LLMService.generatePuzzle`, passing the API key, difficulty, puzzle type, and recent question history.
    * For `EVALUATE_WITH_LLM`, it calls `LLMService.evaluateAnswer`, passing the API key and the relevant question/answer data.
    * It receives the result directly from the `LLMService` (which handles the actual `fetch` call to the Gemini API).
    * It returns this result (e.g., the puzzle object `{question, answer}` or the evaluation result string `'Correct'/'Incorrect'/'Error'`) back to the background script orchestrator.

**Orchestration (`background.js`):**
The main `background.js` script acts as the orchestrator. Its message listener receives the initial request from the popup, retrieves necessary data from Memory (API key, history, score), passes the request through the Perception and Decision-Making layers, invokes the Action layer with the resulting plan, receives the result from the Action layer, updates Memory if necessary (saving the new question to history, updating the score), and finally sends the processed result back to the popup for display.

## Installation (from Source)

1.  Download or clone the project files to a local directory.
2.  Ensure you have obtained a Google AI (Gemini) API Key (see Configuration).
3.  Open Google Chrome and navigate to `chrome://extensions/`.
4.  Enable **Developer mode** using the toggle switch (usually in the top-right corner).
5.  Click the **Load unpacked** button.
6.  Select the directory containing the extension's files (the one with `manifest.json`). The extension should now appear in your list.

## Configuration

1.  **Get API Key:** You need an API key for the Google AI (Gemini) API. You can get one from [Google AI Studio](https://aistudio.google.com/) (free tier available).
2.  **Set API Key:**
    * Right-click the "LLM Puzzle Break" extension icon in your Chrome toolbar and select "Options".
    * Paste your Gemini API key into the input field.
    * Click "Save Settings".
    * **Important:** The extension requires this key to function.

## Usage

1.  Click the LLM Puzzle Break icon in your Chrome toolbar.
2.  The popup will load and display the first puzzle question and your current score (initially 0).
3.  Type your answer into the input field.
4.  Click the "Submit Answer" button (or press Enter).
5.  The extension will show feedback ("Correct!" or "Incorrect. Correct Answer: ...") and update your score if correct.
6.  Use the buttons that appear below the feedback to "Play Again" (using current settings) or select a different **Puzzle Type** or **Difficulty Level** before getting the next question.

## Security Note (API Key)

⚠️ Storing the Google AI API key via the Options page (in `chrome.storage.sync`) is **not secure** for published or shared extensions. This method is intended for **personal development and use only**. If you were to distribute this extension, you would need to implement a secure method for handling API keys, such as user authentication (OAuth) or routing requests through a secure backend proxy server that holds the key.
